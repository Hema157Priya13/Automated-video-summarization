{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**INPUT** : Raw video\n",
        "\n",
        ">\n",
        "\n",
        "\n",
        "**OUTPUT** : Edited micro video of contextual glimpse"
      ],
      "metadata": {
        "id": "mWiaesbwRL7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install all the required packages**\n",
        "\n"
      ],
      "metadata": {
        "id": "NusEAmRkNIrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install elevenlabs\n",
        "!pip install openai-whisper"
      ],
      "metadata": {
        "id": "qhO6me32Eu5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import moviepy.editor as mp\n",
        "import cv2\n",
        "import whisper\n",
        "import os\n",
        "import elevenlabs\n",
        "from langchain.llms import OpenAI\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.utilities.dalle_image_generator import DallEAPIWrapper\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "GgSeCfceHr_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CJaObm4gLaJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Input the Video**"
      ],
      "metadata": {
        "id": "2zdiqodMNygi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSpJDUDVrbOA"
      },
      "outputs": [],
      "source": [
        "clip = mp.VideoFileClip(\"/content/drive/MyDrive/The basics about_ Coffee.mp4\")\n",
        "clip1= clip.subclip(0,20)\n",
        "clip1.ipython_display(width= 300)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract the audio**"
      ],
      "metadata": {
        "id": "XsSzK7ERNlgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract audio\n",
        "audio_clip = mp.AudioFileClip(\"/content/drive/MyDrive/The basics about_ Coffee.mp4\")\n",
        "audio_clip.write_audiofile(\"audio.wav\")\n",
        "audio_clip1 = audio_clip.subclip(0,20)\n",
        "audio_clip1.ipython_display(width= 300)"
      ],
      "metadata": {
        "id": "r5KZ7etRr3LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Transcript the audio to text**"
      ],
      "metadata": {
        "id": "ZYSbEkMVN_8A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base\")\n",
        "result = model.transcribe(\"audio.wav\")\n",
        "with open(\"transcription.txt\", \"w\") as f:\n",
        "  f.write(result['text'])"
      ],
      "metadata": {
        "id": "VKcZulLKX0br"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openapi_key = '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'\n",
        "os.environ['OPENAI_API_KEY']= openapi_key"
      ],
      "metadata": {
        "id": "l_jvuj4zSgbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('transcription.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Printing the first 285 characters as a preview\n",
        "print (text[:285])"
      ],
      "metadata": {
        "id": "Y6DDngj7Sb3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate Summary**"
      ],
      "metadata": {
        "id": "Pra2jnisOS6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.6, model_name='text-davinci-003', openai_api_key=openapi_key)\n",
        "\n",
        "template = \"\"\"\n",
        "%INSTRUCTIONS:\n",
        "Please summarize the following text which is transcript of a video in short.\n",
        "Respond in a manner so that anyone would understand.\n",
        "\n",
        "%TEXT:\n",
        "{text}\n",
        "\"\"\"\n",
        "\n",
        "# Create a LangChain prompt template that we can insert values to later\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=template,\n",
        ")"
      ],
      "metadata": {
        "id": "Z3mauZcZ0U0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_prompt = prompt.format(text=text)\n",
        "print(final_prompt)\n",
        "output = llm(final_prompt)\n",
        "print (output)"
      ],
      "metadata": {
        "id": "JEPbNCTe0-FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name= 'TLDW'\n",
        "folder_path = os.path.join('/content/drive/My Drive', folder_name)\n",
        "os.makedirs(folder_path, exist_ok= True)\n",
        "os.chdir(folder_path)"
      ],
      "metadata": {
        "id": "Y4vRvjZs5Au2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"transcription.txt\", \"w\") as f:\n",
        "  f.write(result['text'])"
      ],
      "metadata": {
        "id": "GZ5FwFPWOvOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('summary.txt', 'w') as f:\n",
        "  f.write(output)"
      ],
      "metadata": {
        "id": "hTHl9bPu5apX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split the summary**"
      ],
      "metadata": {
        "id": "BSbWh-I9O2Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = []\n",
        "with open(\"summary.txt\",'r') as data_file:\n",
        "    for line in data_file:\n",
        "        data = line.split(\". \")\n",
        "        sentences.append(data)"
      ],
      "metadata": {
        "id": "b9otFaNlT_XY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences"
      ],
      "metadata": {
        "id": "f7Uo8fFGX-g9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name= 'audio'\n",
        "folder_path_audio = os.path.join(folder_path, folder_name)\n",
        "os.makedirs(folder_path_audio, exist_ok= True)\n",
        "os.chdir(folder_path_audio)"
      ],
      "metadata": {
        "id": "rIfDYCaV6F4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate audio**"
      ],
      "metadata": {
        "id": "XP9fzuF3PCO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "elevenlabs.set_api_key(\"f76df17680d22a94bdcf97845cdc995e\")\n",
        "for i in range(0,len(sentences[1])):\n",
        "  audio = elevenlabs.generate(\n",
        "      text= sentences[1][i],\n",
        "      voice = \"Dave\" # customize the voice according to requirements\n",
        "  )\n",
        "  elevenlabs.save(audio, f\"audio_{i+1}.mp3\")"
      ],
      "metadata": {
        "id": "dLuhQU_9A1JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name= 'Videos'\n",
        "folder_path_video = os.path.join(folder_path, folder_name)\n",
        "os.makedirs(folder_path_video, exist_ok= True)"
      ],
      "metadata": {
        "id": "RJjnDjAwVciR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generate video for each part of summary (video clips+audio)**"
      ],
      "metadata": {
        "id": "j_ExjxR7PPmA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from moviepy.editor import *"
      ],
      "metadata": {
        "id": "wfiT65ZE6C-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_timestamps = [5,48,125,316]"
      ],
      "metadata": {
        "id": "pTqP8npHe1tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_folder= '/content/drive/MyDrive/TLDW/Videos'\n",
        "audio_folder= '/content/drive/MyDrive/TLDW/audio'\n",
        "for i in range(0,len(sentences[1])):\n",
        "  # Load the audio\n",
        "  audio_path = os.path.join(audio_folder, f'audio_{i+1}.mp3')\n",
        "  audio = AudioFileClip(audio_path)\n",
        "  audio_duration = audio.duration\n",
        "  clip1= clip.subclip(video_timestamps[i],video_timestamps[i]+audio_duration)\n",
        "  new_clip = clip1.without_audio()\n",
        "  final_video = new_clip.set_audio(audio)\n",
        "\n",
        "  # Export the final video\n",
        "  output_path = os.path.join(output_folder, f'video{i+1}.mp4')\n",
        "  final_video.write_videofile(output_path, codec='libx264')\n",
        "\n",
        "  print(\"Video with transitions saved to\", output_path)"
      ],
      "metadata": {
        "id": "UgLG3XrMajRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Concatenate all the videos and get a final video**"
      ],
      "metadata": {
        "id": "c4PErNP5Pik5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_paths= []\n",
        "for i in range(0,len(sentences[1])):\n",
        "  output_path = os.path.join(output_folder, f'video{i+1}.mp4')\n",
        "  video_paths.append(output_path)\n",
        "\n",
        "# Load the video clips\n",
        "video_clips = [VideoFileClip(video_path) for video_path in video_paths]\n",
        "\n",
        "# Concatenate the video clips\n",
        "final_video = concatenate_videoclips(video_clips, method=\"compose\")\n",
        "\n",
        "# Export the final video\n",
        "output_path = os.path.join(output_folder,'combined_video.mp4')\n",
        "final_video.write_videofile(output_path, codec='libx264')"
      ],
      "metadata": {
        "id": "Sc-CYjGhzODi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preview video here\n",
        "clip_final= final_video.subclip(0,25)\n",
        "clip_final.ipython_display(width= 300)"
      ],
      "metadata": {
        "id": "oHP3S1r_f8Wq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Used **Vector store** and embeddings of transcription are stored in the vector store.\n",
        "Therefore, based on similarity search, it is able to answer any question related to video.\n",
        ">\n",
        "Example - Query: What is the video about?\n",
        ">\n",
        "  This provides the summary of the video."
      ],
      "metadata": {
        "id": "Kok6dYvDXOWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-gpu"
      ],
      "metadata": {
        "id": "aJ2vxtGzVa54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings"
      ],
      "metadata": {
        "id": "30A-MtkMQznh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=openapi_key)"
      ],
      "metadata": {
        "id": "JAwGchUAWRtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcription_path = os.path.join(folder_path, 'transcription.txt')\n",
        "loader = TextLoader(transcription_path)\n",
        "doc = loader.load()\n",
        "print (f\"You have {len(doc)} document\")\n",
        "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
      ],
      "metadata": {
        "id": "X_2yZrAETYKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=openapi_key)\n",
        "docsearch = FAISS.from_documents(doc, embeddings)"
      ],
      "metadata": {
        "id": "OMcEw3idVGYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "ZPab_DolVOhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = input(\"query: \")\n",
        "qa.run(query)"
      ],
      "metadata": {
        "id": "3GpuffW8VnXG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}